{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3411543a-b431-4e13-a317-db64a3d915c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration, AdamW\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random\n",
    "import os, json\n",
    "import yaml\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399f605e-a294-4b46-9acc-eca159d4209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rule:\n",
    "    def __init__(self, text, rule):\n",
    "        self.text = text\n",
    "        self.rule = rule\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.text}\\n\\n{self.rule}\\n\\n'\n",
    "\n",
    "class TextRuleT5Dataset:\n",
    "  def __init__(self, rule_list, tokenizer):   \n",
    "    self.rule_list = [y for x in rule_list.values() for y in x]\n",
    "    self.tokenizer = tokenizer\n",
    "    self.input_max_len = INPUT_MAX_LEN\n",
    "    self.output_max_len = OUTPUT_MAX_LEN\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.rule_list)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    text = self.rule_list[idx].text\n",
    "    rule = self.rule_list[idx].rule\n",
    "\n",
    "    input_tokenize = self.tokenizer(      \n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=self.input_max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    output_tokenize = self.tokenizer(\n",
    "        rule,\n",
    "        add_special_tokens=True,\n",
    "        max_length=self.output_max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = input_tokenize[\"input_ids\"].flatten()\n",
    "    attention_mask = input_tokenize[\"attention_mask\"].flatten()\n",
    "    labels = output_tokenize['input_ids'].flatten()\n",
    "\n",
    "    out = {\n",
    "        'text':text,      \n",
    "        'rule':rule,\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask':attention_mask,\n",
    "        'target':labels\n",
    "    }\n",
    "        \n",
    "    return out\n",
    "\n",
    "class TextRuleT5DataLoad(pl.LightningDataModule):\n",
    "    def __init__(self, train_data, val_data, tokenizer):\n",
    "        super().__init__()\n",
    "        self.train_data_raw = train_data\n",
    "        self.val_data_raw = val_data\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_data = TextRuleT5Dataset(self.train_data_raw, self.tokenizer)\n",
    "        self.val_data = TextRuleT5Dataset(self.val_data_raw, self.tokenizer)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "          self.train_data,\n",
    "          batch_size=TRAIN_BATCH_SIZE,\n",
    "          shuffle=True, \n",
    "          num_workers=2\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "          self.val_data,\n",
    "          batch_size=VAL_BATCH_SIZE,\n",
    "          num_workers=2\n",
    "        )\n",
    "\n",
    "class TextRuleT5Model(pl.LightningModule):  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.model(\n",
    "          input_ids=input_ids, \n",
    "          attention_mask=attention_mask, \n",
    "          labels=labels\n",
    "        )\n",
    "        return output.loss, output.logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"target\"]\n",
    "        loss, logits = self(input_ids , attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"target\"]\n",
    "        loss, logits = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=0.0001)\n",
    "\n",
    "def read_yaml_files(directory):\n",
    "    all_yaml_content = {}\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".yml\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "                rules = data['rules']\n",
    "                for rule in rules:\n",
    "                    all_yaml_content[rule['name']] = rule['pattern']\n",
    "\n",
    "    return all_yaml_content\n",
    "\n",
    "def read_json_files(directory):\n",
    "    all_json_content = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                    all_json_content.extend(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\n",
    "                        f\"Error reading {filename}. File might not be a valid JSON.\")\n",
    "\n",
    "    return all_json_content\n",
    "\n",
    "def mini_parse_event_rule(value):\n",
    "    sents = value.split(\"\\n\")\n",
    "    sents = [sent.split('#')[0].strip() for sent in sents]\n",
    "    sents = [sent for sent in sents if sent]\n",
    "\n",
    "    if len(sents) >= 3:\n",
    "        args = defaultdict(str)\n",
    "        possible_args = set(\n",
    "            [\"trigger\", \"controlled:BioEntity\", \"controller:PossibleController\"]\n",
    "        )\n",
    "        current_arg = \"\"\n",
    "\n",
    "        for sent in sents:\n",
    "            found = False\n",
    "            for arg in possible_args:\n",
    "                if arg + ' = ' in sent:\n",
    "                    current_arg = arg\n",
    "                    args[current_arg] = sent + \"\\n\"\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                args[current_arg] += sent + \"\\n\"\n",
    "\n",
    "        trigger = args[\"trigger\"]\n",
    "        controlled = args[\"controlled:BioEntity\"]\n",
    "        controller = args[\"controller:PossibleController\"]\n",
    "        return (trigger, controlled, controller)\n",
    "\n",
    "    return ('','','')\n",
    "\n",
    "def add_special_tags(tokens, lemmas, tags, outgoing, incoming):\n",
    "    new_tokens = []\n",
    "\n",
    "    for i in range(len(tokens)):\n",
    "        new_token = \"\"\n",
    "        new_token += \"(word: \" + tokens[i] + \", \"\n",
    "        new_token += \"lemma: \" + lemmas[i] + \", \"\n",
    "        new_token += \"tag: \" + tags[i] + \", \"\n",
    "        new_token += \"outgoing: (\" + outgoing[i].strip() + \"), \"\n",
    "        new_token += \"incoming: (\" + incoming[i].strip() + \")) \"\n",
    "        new_tokens.append(new_token)\n",
    "\n",
    "    return new_tokens\n",
    "\n",
    "def add_special_tokens(tokens, cr_range, cd_range, tr_range):\n",
    "    i = 0\n",
    "    new_tokens = []\n",
    "    cr1, cr2 = cr_range[0], cr_range[-1]\n",
    "    cd1, cd2 = cd_range[0], cd_range[-1]\n",
    "    tr1, tr2 = tr_range[0], tr_range[-1]\n",
    "\n",
    "    while i < len(tokens):\n",
    "        if i == cr1:\n",
    "            new_tokens.append('<controller>')\n",
    "            new_tokens.extend(tokens[cr1:cr2])\n",
    "            new_tokens.append('</controller>')\n",
    "            i += cr2 - cr1\n",
    "        elif i == cd1:\n",
    "            new_tokens.append('<controlled>')\n",
    "            new_tokens.extend(tokens[cd1:cd2])\n",
    "            new_tokens.append('</controlled>')\n",
    "            i += cd2 - cd1\n",
    "        elif i == tr1:\n",
    "            new_tokens.append('<trigger>')\n",
    "            new_tokens.extend(tokens[tr1:tr2])\n",
    "            new_tokens.append('</trigger>')\n",
    "            i += tr2 - tr1\n",
    "        else:\n",
    "            new_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "\n",
    "    return new_tokens\n",
    "\n",
    "def run(tokenizer):\n",
    "    dataload = TextRuleT5DataLoad(train_rules, val_rules, tokenizer)\n",
    "    dataload.setup()\n",
    "    device = DEVICE\n",
    "    model = TextRuleT5Model()\n",
    "    model.to(device)\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"text_rule_t5_model\",\n",
    "        filename=\"best-model\",\n",
    "        save_top_k=1,\n",
    "        verbose=True,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\"\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        callbacks=[early_stopping, checkpoint_callback],\n",
    "        max_epochs=EPOCHS,\n",
    "        accelerator=\"auto\"\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, dataload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a9b88f0-931b-4074-b547-e280ad93d091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11422 1554\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(100)\n",
    "\n",
    "yaml_data = read_yaml_files(\"main/src/main/resources/org/clulab/reach/biogrammar/rule_explosion\")\n",
    "json_data = read_json_files(\"training_data/\")\n",
    "proc_data = []\n",
    "\n",
    "for item in json_data:\n",
    "    triggers = []\n",
    "    controlleds = []\n",
    "    controllers = []\n",
    "    rule = item['rule']\n",
    "    rule_name = rule['rule_name']\n",
    "    sentence_tokens = rule['sentence_tokens']\n",
    "    trigger_indices = rule['trigger_indices']\n",
    "    controlled_indices = rule['controlled_indices']\n",
    "    controller_indices = rule['controller_indices']\n",
    "    subrules = item['subrules']\n",
    "    for subrule in subrules:\n",
    "        subrule_name = subrule['rule_name']\n",
    "        if 'trigger' in subrule_name:\n",
    "            if subrule_name in yaml_data:\n",
    "                trigger, controlled, controller = mini_parse_event_rule(yaml_data[subrule_name])\n",
    "                triggers.append(trigger)\n",
    "        elif 'controlled' in subrule_name:\n",
    "            if subrule_name in yaml_data:\n",
    "                trigger, controlled, controller = mini_parse_event_rule(yaml_data[subrule_name])\n",
    "                controlleds.append(controlled)\n",
    "        elif 'controller' in subrule_name:\n",
    "            if subrule_name in yaml_data:\n",
    "                trigger, controlled, controller = mini_parse_event_rule(yaml_data[subrule_name])\n",
    "                controllers.append(controller)\n",
    "    item['triggers'] = triggers\n",
    "    item['controlleds'] = controlleds\n",
    "    item['controllers'] = controllers\n",
    "    new_subrule_count = 0\n",
    "    new_subrules = []\n",
    "    stop_making_rules = False\n",
    "    for trigger in triggers:\n",
    "        for controlled in controlleds:\n",
    "            for controller in controllers:\n",
    "                new_subrules.append(trigger + controlled + controller)\n",
    "                if False: # new_subrule_count >= 1000:\n",
    "                    stop_making_rules = True\n",
    "                    break\n",
    "            if stop_making_rules:\n",
    "                break\n",
    "        if stop_making_rules:\n",
    "            break\n",
    "    item['new_subrules'] = new_subrules\n",
    "    for new_subrule in new_subrules:\n",
    "        proc_data_entry = {}\n",
    "        proc_data_entry['sentence_tokens'] = sentence_tokens\n",
    "        proc_data_entry['base_rule_name'] = rule_name\n",
    "        proc_data_entry['trigger_indices'] = trigger_indices\n",
    "        proc_data_entry['controlled_indices'] = controlled_indices\n",
    "        proc_data_entry['controller_indices'] = controller_indices\n",
    "        proc_data_entry['lemmas'] = rule['lemmas']\n",
    "        proc_data_entry['tags'] = rule['tags']\n",
    "        proc_data_entry['outgoing'] = rule['outgoing']\n",
    "        proc_data_entry['incoming'] = rule['incoming']\n",
    "        proc_data_entry['rule'] = new_subrule\n",
    "        proc_data.append(proc_data_entry)\n",
    "\n",
    "random.shuffle(proc_data)\n",
    "\n",
    "per_rule = defaultdict(int)\n",
    "rule_list = []\n",
    "for item in proc_data:\n",
    "    rule_name = item['base_rule_name']\n",
    "    per_rule[rule_name] += 1\n",
    "    if per_rule[rule_name] <= 1000:\n",
    "        rule_list.append(item)\n",
    "\n",
    "for i in range(len(rule_list)):\n",
    "    rule = rule_list[i]\n",
    "    tokens = rule['sentence_tokens']\n",
    "    lemmas = rule['lemmas']\n",
    "    tags = rule['tags']\n",
    "    incoming = rule['incoming']\n",
    "    outgoing = rule['outgoing']\n",
    "    new_tokens = add_special_tags(tokens, lemmas, tags, outgoing, incoming)\n",
    "    rule_list[i]['new_tokens'] = new_tokens\n",
    "\n",
    "rule_data = defaultdict(list)\n",
    "\n",
    "for i in range(len(rule_list)):\n",
    "    rule = rule_list[i]\n",
    "    tokens = rule['new_tokens']\n",
    "    controller_range = rule['controller_indices']\n",
    "    controlled_range = rule['controlled_indices']\n",
    "    trigger_range = rule['trigger_indices']\n",
    "    rule_name = rule['base_rule_name']\n",
    "    new_tokens = add_special_tokens(tokens, controller_range, controlled_range, trigger_range)\n",
    "    rule_data[rule_name].append(Rule(' '.join(new_tokens), rule['rule'].strip()))\n",
    "\n",
    "train_size = int(0.6 * len(rule_data))\n",
    "train_rules = dict(itertools.islice(rule_data.items(), train_size))\n",
    "val_rules = dict(itertools.islice(rule_data.items(), train_size, None))\n",
    "\n",
    "train_rules_size = len([y for x in train_rules.values() for y in x])\n",
    "val_rules_size = len([y for x in val_rules.values() for y in x])\n",
    "print(train_rules_size, val_rules_size)\n",
    "\n",
    "# params\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "INPUT_MAX_LEN = 3328 #input length\n",
    "OUTPUT_MAX_LEN = 256 # output length\n",
    "TRAIN_BATCH_SIZE = 4 # batch size of training\n",
    "VAL_BATCH_SIZE = 2 # batch size for validation\n",
    "EPOCHS = 100 # number of epoch\n",
    "MODEL_NAME = 'Salesforce/codet5-small'\n",
    "\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "# run(roberta_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1b0b2a-a042-42a1-bc81-443bb85eccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rule(text, trained_model, tokenizer):\n",
    "    inputs_encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length= INPUT_MAX_LEN,\n",
    "        padding = 'max_length',\n",
    "        truncation='only_first',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    device = next(trained_model.parameters()).device\n",
    "\n",
    "    inputs_encoding[\"input_ids\"] = inputs_encoding[\"input_ids\"].to(device)\n",
    "    inputs_encoding[\"attention_mask\"] = inputs_encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    generate_ids = trained_model.model.generate(\n",
    "        input_ids=inputs_encoding[\"input_ids\"],\n",
    "        attention_mask=inputs_encoding[\"attention_mask\"],\n",
    "        max_length=INPUT_MAX_LEN,\n",
    "        num_beams=1,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=1,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "\n",
    "    preds = [\n",
    "        tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        for gen_id in generate_ids\n",
    "    ]\n",
    "\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c097d6-f350-4d7b-88b6-2bc549511427",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = TextRuleT5Model.load_from_checkpoint('text_rule_t5_model/best-model.ckpt')\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdb5e4e4-c9fe-423d-987f-191b8a5af9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Rule name Positive_activation_syntax_7_noun\n",
      "\n",
      "--------------------\n",
      "Text:  (word: Furthermore, lemma: furthermore, tag: RB, outgoing: (), incoming: ((12,advmod)))  (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  <controller> (word: TGF, lemma: tgf, tag: NN, outgoing: ((4,dep)), incoming: ((12,nsubjpass)))  (word: -, lemma: -, tag: :, outgoing: (), incoming: ())  (word: beta, lemma: beta, tag: NN, outgoing: ((7,dep)), incoming: ((2,dep)))  </controller> (word: -, lemma: -, tag: :, outgoing: (), incoming: ())  (word: mediated, lemma: mediated, tag: JJ, outgoing: (), incoming: ((7,amod)))  <trigger> (word: induction, lemma: induction, tag: NN, outgoing: ((6,amod) (9,nmod_of)), incoming: ((4,dep)))  </trigger> (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((9,case)))  <controlled> (word: CTGF, lemma: ctgf, tag: NN, outgoing: ((8,case)), incoming: ((7,nmod_of)))  </controlled> (word: can, lemma: can, tag: MD, outgoing: (), incoming: ((12,aux)))  (word: be, lemma: be, tag: VB, outgoing: (), incoming: ((12,auxpass)))  (word: inhibited, lemma: inhibit, tag: VBN, outgoing: ((0,advmod) (2,nsubjpass) (10,aux) (11,auxpass) (15,nmod_under)), incoming: ())  (word: under, lemma: under, tag: IN, outgoing: (), incoming: ((15,case)))  (word: hypoxic, lemma: hypoxic, tag: JJ, outgoing: (), incoming: ((15,amod)))  (word: conditions, lemma: condition, tag: NNS, outgoing: ((13,case) (14,amod)), incoming: ((12,nmod_under)))  (word: ., lemma: ., tag: ., outgoing: (), incoming: ()) \n",
      "\n",
      "Predicted Rule:  ['trigger = [word=/(?i)^(induc)/ & tag:^N /] [-+nmod_of, 2}\\ncontroller :PossibleController | appos|conj|\\\\xsub jpass\\\\ycompound \\\\b\\' ndep-npcm\\':poss\"/{1,2 }']\n",
      "\n",
      "True Rule:  trigger = [word=/(?i)^(induc)/ & tag=/^N/] [lemma=/^(activ)/ & tag=/^N/]?\n",
      "controlled:BioEntity = (/nmod_of/ /conj/{,2}){1,2}\n",
      "controller:PossibleController = </dep/ /amod/{,2}\n",
      "\n",
      "--------------------\n",
      "Rule name Positive_activation_syntax_2_noun\n",
      "\n",
      "--------------------\n",
      "Text:  (word: The, lemma: the, tag: DT, outgoing: (), incoming: ((1,det)))  (word: effects, lemma: effect, tag: NNS, outgoing: ((0,det) (5,nmod_of)), incoming: ((14,nsubjpass)))  (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((5,case)))  (word: diverse, lemma: diverse, tag: JJ, outgoing: (), incoming: ((5,amod)))  (word: bitter, lemma: bitter, tag: JJ, outgoing: (), incoming: ((5,amod)))  (word: substances, lemma: substance, tag: NNS, outgoing: ((2,case) (3,amod) (4,amod) (8,nmod_on)), incoming: ((1,nmod_of)))  (word: on, lemma: on, tag: IN, outgoing: (), incoming: ((8,case)))  (word: cellular, lemma: cellular, tag: JJ, outgoing: (), incoming: ((8,amod)))  (word: functions, lemma: function, tag: NNS, outgoing: ((6,case) (7,amod) (11,nmod_in)), incoming: ((5,nmod_on)))  (word: in, lemma: in, tag: IN, outgoing: (), incoming: ((11,case)))  (word: cancer, lemma: cancer, tag: NN, outgoing: (), incoming: ((11,compound)))  (word: cells, lemma: cell, tag: NNS, outgoing: ((9,case) (10,compound)), incoming: ((8,nmod_in)))  (word: have, lemma: have, tag: VBP, outgoing: (), incoming: ((14,aux)))  (word: been, lemma: be, tag: VBN, outgoing: (), incoming: ((14,auxpass)))  (word: analysed, lemma: analyse, tag: VBN, outgoing: ((1,nsubjpass) (12,aux) (13,auxpass) (17,nmod_in) (37,ccomp)), incoming: ())  (word: in, lemma: in, tag: IN, outgoing: (), incoming: ((17,case)))  (word: several, lemma: several, tag: JJ, outgoing: (), incoming: ((17,amod)))  (word: studies, lemma: study, tag: NNS, outgoing: ((15,case) (16,amod)), incoming: ((14,nmod_in)))  (word: [, lemma: [, tag: -LRB-, outgoing: (), incoming: ())  (word: 17,18,19,20,21,22,26, lemma: 17,18,19,20,21,22,26, tag: CD, outgoing: ((21,ref) (23,acl:relcl)), incoming: ((23,nsubjpass) (37,nsubj)))  (word: ], lemma: ], tag: -RRB-, outgoing: (), incoming: ())  (word: that, lemma: that, tag: WDT, outgoing: (), incoming: ((19,ref)))  (word: are, lemma: be, tag: VBP, outgoing: (), incoming: ((23,auxpass)))  (word: discussed, lemma: discuss, tag: VBN, outgoing: ((19,nsubjpass) (22,auxpass) (28,nmod_in)), incoming: ((19,acl:relcl)))  (word: in, lemma: in, tag: IN, outgoing: (), incoming: ((28,case)))  (word: the, lemma: the, tag: DT, outgoing: (), incoming: ((28,det)))  (word: following, lemma: follow, tag: VBG, outgoing: (), incoming: ((28,amod)))  (word: paragraphs.The, lemma: paragraphs.the, tag: NN, outgoing: (), incoming: ((28,compound)))  <trigger> (word: activation, lemma: activation, tag: NN, outgoing: ((24,case) (25,det) (26,amod) (27,compound) (30,nmod_of) (32,nmod_of) (34,nmod_by) (36,nmod_by)), incoming: ((23,nmod_in)))  </trigger> (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((30,case)))  (word: TAS2R4, lemma: tas2r4, tag: NN, outgoing: ((29,case) (31,cc) (32,conj_and)), incoming: ((28,nmod_of)))  (word: and, lemma: and, tag: CC, outgoing: (), incoming: ((30,cc)))  <controlled> (word: TAS2R14, lemma: tas2r14, tag: NN, outgoing: (), incoming: ((28,nmod_of) (30,conj_and)))  </controlled> (word: by, lemma: by, tag: IN, outgoing: (), incoming: ((34,case)))  (word: quinine, lemma: quinine, tag: NN, outgoing: ((33,case) (35,cc) (36,conj_or)), incoming: ((28,nmod_by)))  (word: or, lemma: or, tag: CC, outgoing: (), incoming: ((34,cc)))  <controller> (word: apigenin, lemma: apigenin, tag: NN, outgoing: (), incoming: ((28,nmod_by) (34,conj_or)))  </controller> (word: led, lemma: lead, tag: VBD, outgoing: ((19,nsubj) (43,nmod_to) (46,nmod_in) (68,advcl_while)), incoming: ((14,ccomp)))  (word: to, lemma: to, tag: TO, outgoing: (), incoming: ((43,case)))  (word: a, lemma: a, tag: DT, outgoing: (), incoming: ((43,det)))  (word: significant, lemma: significant, tag: JJ, outgoing: (), incoming: ((43,amod)))  (word: concentration, lemma: concentration, tag: NN, outgoing: (), incoming: ((43,compound)))  (word: dependent, lemma: dependent, tag: JJ, outgoing: (), incoming: ((43,amod)))  (word: reduction, lemma: reduction, tag: NN, outgoing: ((38,case) (39,det) (40,amod) (41,compound) (42,amod)), incoming: ((37,nmod_to)))  (word: in, lemma: in, tag: IN, outgoing: (), incoming: ((46,case)))  (word: cell, lemma: cell, tag: NN, outgoing: (), incoming: ((46,compound)))  (word: proliferation, lemma: proliferation, tag: NN, outgoing: ((44,case) (45,compound) (53,nmod_of)), incoming: ((37,nmod_in)))  (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((53,case)))  (word: the, lemma: the, tag: DT, outgoing: (), incoming: ((53,det)))  (word: breast, lemma: breast, tag: NN, outgoing: (), incoming: ((53,compound)))  (word: cancer, lemma: cancer, tag: NN, outgoing: (), incoming: ((53,compound)))  (word: cell, lemma: cell, tag: NN, outgoing: (), incoming: ((53,compound)))  (word: line, lemma: line, tag: NN, outgoing: (), incoming: ((53,compound)))  (word: MDA-MB-231, lemma: mda-mb-231, tag: NN, outgoing: ((47,case) (48,det) (49,compound) (50,compound) (51,compound) (52,compound)), incoming: ((46,nmod_of)))  (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: while, lemma: while, tag: IN, outgoing: (), incoming: ((68,mark)))  (word: proliferation, lemma: proliferation, tag: NN, outgoing: ((58,nmod_of) (62,appos)), incoming: ((68,nsubjpass)))  (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((58,case)))  (word: MCF-10A, lemma: mcf-10a, tag: NN, outgoing: ((57,case)), incoming: ((56,nmod_of)))  (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: the, lemma: the, tag: DT, outgoing: (), incoming: ((62,det)))  (word: normal, lemma: normal, tag: JJ, outgoing: (), incoming: ((62,amod)))  (word: breast, lemma: breast, tag: NN, outgoing: ((60,det) (61,amod) (64,dep)), incoming: ((56,appos)))  (word: epithelial, lemma: epithelial, tag: JJ, outgoing: (), incoming: ((64,amod)))  (word: cells, lemma: cell, tag: NNS, outgoing: ((63,amod)), incoming: ((62,dep)))  (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: was, lemma: be, tag: VBD, outgoing: (), incoming: ((68,auxpass)))  (word: only, lemma: only, tag: RB, outgoing: (), incoming: ((68,advmod)))  (word: attenuated, lemma: attenuate, tag: VBN, outgoing: ((55,mark) (56,nsubjpass) (66,auxpass) (67,advmod) (72,nmod_at)), incoming: ((37,advcl_while)))  (word: at, lemma: at, tag: IN, outgoing: (), incoming: ((72,case)))  (word: higher, lemma: higher, tag: JJR, outgoing: (), incoming: ((72,amod)))  (word: ligand, lemma: ligand, tag: NN, outgoing: (), incoming: ((72,compound)))  (word: concentrations, lemma: concentration, tag: NNS, outgoing: ((69,case) (70,amod) (71,compound) (74,nmod)), incoming: ((68,nmod_at)))  (word: [, lemma: [, tag: -LRB-, outgoing: (), incoming: ())  (word: 17, lemma: 17, tag: CD, outgoing: (), incoming: ((72,nmod)))  (word: ], lemma: ], tag: -RRB-, outgoing: (), incoming: ())  (word: ., lemma: ., tag: ., outgoing: (), incoming: ()) \n",
      "\n",
      "Predicted Rule:  ['trigger = [word=/(?i)^(activat)/ & tag:^N-] [-lemma=\"regulate\"&!outgoing={,2}\\ncontroller :PossibleController | appos|conj|\\\\nsub jpass /\\'</\\'?']\n",
      "\n",
      "True Rule:  trigger = [word=/(?i)^(activat)/ & tag=/^N/] [lemma=/^(activ)/ & tag=/^N/]?\n",
      "controlled:BioEntity = /nmod_of/? /conj_/{1,2}\n",
      "controller:PossibleController = /nmod_of/? /nmod_by/ /conj_/{,2}\n",
      "\n",
      "--------------------\n",
      "Rule name Positive_activation_syntax_noun_Hearst\n",
      "\n",
      "--------------------\n",
      "Text:  (word: Importantly, lemma: importantly, tag: RB, outgoing: (), incoming: ((32,advmod)))  (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: except, lemma: except, tag: IN, outgoing: ((3,mwe)), incoming: ((4,case)))  (word: for, lemma: for, tag: IN, outgoing: (), incoming: ((2,mwe)))  (word: p300, lemma: p300, tag: NN, outgoing: ((2,case) (5,cc) (6,conj_and) (7,ref) (15,acl:relcl)), incoming: ((8,nmod:poss) (32,nmod_except_for)))  (word: and, lemma: and, tag: CC, outgoing: (), incoming: ((4,cc)))  (word: CBP, lemma: cbp, tag: NN, outgoing: (), incoming: ((4,conj_and) (8,nmod:poss) (32,nmod_except_for)))  (word: whose, lemma: whose, tag: WP$, outgoing: (), incoming: ((4,ref)))  (word: labeling, lemma: labeling, tag: NN, outgoing: ((4,nmod:poss) (6,nmod:poss) (11,nmod_by)), incoming: ((15,nsubj)))  (word: by, lemma: by, tag: IN, outgoing: (), incoming: ((11,case)))  (word: PYGO2-BirA, lemma: pygo2-bira, tag: NN, outgoing: (), incoming: ((11,compound)))  (word: *, lemma: *, tag: NN, outgoing: ((9,case) (10,compound)), incoming: ((8,nmod_by)))  (word: was, lemma: be, tag: VBD, outgoing: (), incoming: ((15,cop)))  (word: moderately, lemma: moderately, tag: RB, outgoing: (), incoming: ((15,advmod)))  (word: Wnt, lemma: wnt, tag: NN, outgoing: (), incoming: ((15,nmod:npmod)))  (word: inducible, lemma: inducible, tag: JJ, outgoing: ((8,nsubj) (12,cop) (13,advmod) (14,nmod:npmod) (18,dep)), incoming: ((4,acl:relcl)))  (word: (, lemma: (, tag: -LRB-, outgoing: (), incoming: ())  (word: ~, lemma: ~, tag: SYM, outgoing: (), incoming: ((18,dep)))  (word: 3x, lemma: 3x, tag: FW, outgoing: ((17,dep)), incoming: ((15,dep)))  (word: ), lemma: ), tag: -RRB-, outgoing: (), incoming: ())  (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: all, lemma: all, tag: DT, outgoing: (), incoming: ((23,det)))  (word: other, lemma: other, tag: JJ, outgoing: (), incoming: ((23,amod)))  (word: components, lemma: component, tag: NNS, outgoing: ((21,det) (22,amod) (27,nmod_of) (30,nmod_of)), incoming: ((32,nsubjpass)))  (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((27,case)))  (word: the, lemma: the, tag: DT, outgoing: (), incoming: ((27,det)))  (word: Wnt, lemma: wnt, tag: NN, outgoing: (), incoming: ((27,compound)))  (word: enhanceosome, lemma: enhanceosome, tag: NN, outgoing: ((24,case) (25,det) (26,compound) (28,cc) (30,conj_and)), incoming: ((23,nmod_of)))  (word: and, lemma: and, tag: CC, outgoing: (), incoming: ((27,cc)))  (word: BAF, lemma: baf, tag: NN, outgoing: (), incoming: ((30,compound)))  (word: complex, lemma: complex, tag: NN, outgoing: ((29,compound)), incoming: ((23,nmod_of) (27,conj_and)))  (word: were, lemma: be, tag: VBD, outgoing: (), incoming: ((32,auxpass)))  (word: labeled, lemma: label, tag: VBN, outgoing: ((0,advmod) (4,nmod_except_for) (6,nmod_except_for) (23,nsubjpass) (31,auxpass) (35,nmod_with) (39,nmod_regardless_of)), incoming: ())  (word: with, lemma: with, tag: IN, outgoing: (), incoming: ((35,case)))  (word: similar, lemma: similar, tag: JJ, outgoing: (), incoming: ((35,amod)))  (word: efficiency, lemma: efficiency, tag: NN, outgoing: ((33,case) (34,amod)), incoming: ((32,nmod_with)))  (word: regardless, lemma: regardless, tag: RB, outgoing: ((37,mwe)), incoming: ((39,case)))  (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((36,mwe)))  <controlled> (word: Wnt, lemma: wnt, tag: NN, outgoing: (), incoming: ((39,compound)))  </controlled> <trigger> (word: signaling, lemma: signaling, tag: NN, outgoing: ((36,case) (38,compound) (42,nmod_including) (44,nmod_including)), incoming: ((32,nmod_regardless_of)))  </trigger> (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: including, lemma: include, tag: VBG, outgoing: (), incoming: ((42,case)))  <controller> (word: TCF1/3/4, lemma: tcf1/3/4, tag: NN, outgoing: ((41,case) (43,cc) (44,conj_and) (47,appos)), incoming: ((39,nmod_including)))  </controller> (word: and, lemma: and, tag: CC, outgoing: (), incoming: ((42,cc)))  (word: LEF1, lemma: lef1, tag: NN, outgoing: (), incoming: ((39,nmod_including) (42,conj_and)))  (word: (, lemma: (, tag: -LRB-, outgoing: (), incoming: ())  (word: Figure, lemma: Figure, tag: NNP, outgoing: (), incoming: ((47,compound)))  (word: 4D, lemma: 4d, tag: NN, outgoing: ((46,compound)), incoming: ((42,appos)))  (word: ), lemma: ), tag: -RRB-, outgoing: (), incoming: ())  (word: ., lemma: ., tag: ., outgoing: (), incoming: ()) \n",
      "\n",
      "Predicted Rule:  ['trigger = [word=/(?i)^(signal)/ & tag:^N-] [-lemma=\"regard\"&!outgoing=%s]\" /compound/{,2}\\ncontroller :PossibleController, 2 }']\n",
      "\n",
      "True Rule:  trigger = [word=/(?i)^(signal)/ & tag=/^N/] [lemma=/^(regul)/ & tag=/^N/]?\n",
      "controlled:BioEntity = /compound/{,2}\n",
      "controller:PossibleController = /nmod_(including)/ (nummod)?\n",
      "\n",
      "--------------------\n",
      "Rule name Positive_activation_syntax_8_verb\n",
      "\n",
      "--------------------\n",
      "Text:  (word: Concerning, lemma: concern, tag: VBG, outgoing: (), incoming: ((2,case)))  (word: cervical, lemma: cervical, tag: JJ, outgoing: (), incoming: ((2,amod)))  (word: cancer, lemma: cancer, tag: NN, outgoing: ((0,case) (1,amod)), incoming: ((5,nmod_concerning)))  (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: hsa-miR-133a, lemma: hsa-mir-133a, tag: NN, outgoing: (), incoming: ((5,nsubj)))  (word: appears, lemma: appear, tag: VBZ, outgoing: ((2,nmod_concerning) (4,nsubj) (6,xcomp)), incoming: ())  (word: downregulated, lemma: downregulate, tag: VBN, outgoing: ((8,nmod_by)), incoming: ((5,xcomp)))  (word: by, lemma: by, tag: IN, outgoing: (), incoming: ((8,case)))  <controller> (word: NEAT1, lemma: neat1, tag: NN, outgoing: ((7,case) (10,ref) (13,acl:relcl)), incoming: ((6,nmod_by) (13,nsubj)))  </controller> (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: which, lemma: which, tag: WDT, outgoing: (), incoming: ((8,ref)))  (word: in, lemma: in, tag: IN, outgoing: (), incoming: ((12,case)))  (word: turn, lemma: turn, tag: NN, outgoing: ((11,case)), incoming: ((13,nmod_in)))  <trigger> (word: results, lemma: result, tag: VBZ, outgoing: ((8,nsubj) (12,nmod_in) (15,nmod_in)), incoming: ((8,acl:relcl)))  (word: in, lemma: in, tag: IN, outgoing: (), incoming: ((15,case)))  (word: upregulation, lemma: upregulation, tag: NN, outgoing: ((14,case) (21,nmod_of)), incoming: ((13,nmod_in)))  </trigger> (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((21,case)))  <controlled> (word: SOX4, lemma: sox4, tag: NN, outgoing: ((18,cc) (19,conj_and)), incoming: ((21,compound)))  </controlled> (word: and, lemma: and, tag: CC, outgoing: (), incoming: ((17,cc)))  (word: cervical, lemma: cervical, tag: JJ, outgoing: (), incoming: ((17,conj_and) (21,compound)))  (word: cancer, lemma: cancer, tag: NN, outgoing: (), incoming: ((21,compound)))  (word: progression, lemma: progression, tag: NN, outgoing: ((16,case) (17,compound) (19,compound) (20,compound) (23,nmod)), incoming: ((15,nmod_of)))  (word: [, lemma: [, tag: -LRB-, outgoing: (), incoming: ())  (word: 60, lemma: 60, tag: CD, outgoing: (), incoming: ((21,nmod)))  (word: ], lemma: ], tag: -RRB-, outgoing: (), incoming: ())  (word: ., lemma: ., tag: ., outgoing: (), incoming: ()) \n",
      "\n",
      "Predicted Rule:  ['trigger = [word=/(?i)^(results)/ & tag:^V /\\'nmod\\':np mod,!outgoing=[<]\\' nsubj-=\\'sensitivity\\',notifier_id=\"cantbor\"&!outside--\\ncontrolled:\\'NModIn$1\\'t|in$\\'] | appos} </\\'con j/{;2,}']\n",
      "\n",
      "True Rule:  trigger = [lemma=result] in [word=/(?i)^(upregul)/]\n",
      "controlled:BioEntity = nmod_of /compound/?\n",
      "controller:PossibleController = nsubj /appos/{,2}\n",
      "\n",
      "--------------------\n",
      "Rule name Negative_activation_syntax_noun_Hearst\n",
      "\n",
      "--------------------\n",
      "Text:  (word: Furthermore, lemma: furthermore, tag: RB, outgoing: (), incoming: ((13,advmod)))  (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: proteinases, lemma: proteinase, tag: NNS, outgoing: ((8,nmod_such_as)), incoming: ((13,nsubj)))  (word: such, lemma: such, tag: JJ, outgoing: ((4,mwe)), incoming: ((8,case)))  (word: as, lemma: as, tag: IN, outgoing: (), incoming: ((3,mwe)))  (word: elastase, lemma: elastase, tag: NN, outgoing: ((6,cc) (7,conj_and)), incoming: ((8,compound)))  (word: and, lemma: and, tag: CC, outgoing: (), incoming: ((5,cc)))  (word: cathepsin, lemma: cathepsin, tag: NN, outgoing: (), incoming: ((5,conj_and) (8,compound)))  (word: G, lemma: g, tag: NN, outgoing: ((3,case) (5,compound) (7,compound) (12,nmod_from)), incoming: ((2,nmod_such_as)))  (word: from, lemma: from, tag: IN, outgoing: (), incoming: ((12,case)))  (word: the, lemma: the, tag: DT, outgoing: (), incoming: ((12,det)))  (word: released, lemma: released, tag: JJ, outgoing: (), incoming: ((12,amod)))  (word: NETs, lemma: net, tag: NNS, outgoing: ((9,case) (10,det) (11,amod)), incoming: ((8,nmod_from)))  (word: degrade, lemma: degrade, tag: VB, outgoing: ((0,advmod) (2,nsubj) (16,dobj)), incoming: ())  (word: physiological, lemma: physiological, tag: JJ, outgoing: (), incoming: ((16,amod)))  <controlled> (word: coagulation, lemma: coagulation, tag: NN, outgoing: (), incoming: ((16,compound)))  </controlled> <trigger> (word: inhibitors, lemma: inhibitor, tag: NNS, outgoing: ((14,amod) (15,compound) (22,nmod_such_as) (29,acl:relcl)), incoming: ((13,dobj)))  </trigger> (word: such, lemma: such, tag: JJ, outgoing: ((18,mwe)), incoming: ((22,case)))  (word: as, lemma: as, tag: IN, outgoing: (), incoming: ((17,mwe)))  <controller> (word: tissue, lemma: tissue, tag: NN, outgoing: (), incoming: ((22,compound)))  (word: factor, lemma: factor, tag: NN, outgoing: (), incoming: ((22,compound)))  (word: pathway, lemma: pathway, tag: NN, outgoing: (), incoming: ((22,compound)))  (word: inhibitor, lemma: inhibitor, tag: NN, outgoing: ((17,case) (19,compound) (20,compound) (21,compound) (24,appos)), incoming: ((16,nmod_such_as)))  </controller> (word: (, lemma: (, tag: -LRB-, outgoing: (), incoming: ())  (word: TFPI, lemma: tfpi, tag: NN, outgoing: (), incoming: ((22,appos)))  (word: ), lemma: ), tag: -RRB-, outgoing: (), incoming: ())  (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: thereby, lemma: thereby, tag: RB, outgoing: (), incoming: ((29,advmod)))  (word: accelerating, lemma: accelerate, tag: VBG, outgoing: (), incoming: ((29,amod)))  (word: coagulation, lemma: coagulation, tag: NN, outgoing: ((27,advmod) (28,amod) (31,nmod)), incoming: ((16,acl:relcl)))  (word: [, lemma: [, tag: -LRB-, outgoing: (), incoming: ())  (word: 57, lemma: 57, tag: CD, outgoing: (), incoming: ((29,nmod)))  (word: ], lemma: ], tag: -RRB-, outgoing: (), incoming: ())  (word: ., lemma: ., tag: ., outgoing: (), incoming: ()) \n",
      "\n",
      "Predicted Rule:  ['trigger = [word=/(?i)^(inhibit)/ & tag:^N-] [-lemma=\"regulate\"&!outgoing={}\\ncontrolled:\"nsubj\":x sub j } /compound/{,2}']\n",
      "\n",
      "True Rule:  trigger = [word=/(?i)^(inhibit)/ & tag=/^N/] [lemma=/^(regul)/ & tag=/^N/]?\n",
      "controlled:BioEntity = /compound/{,2}\n",
      "controller:PossibleController = /nmod_(such_as)/ (compound)?\n",
      "\n",
      "--------------------\n",
      "Rule name Negative_activation_copula_1\n",
      "\n",
      "--------------------\n",
      "Text:  (word: Sfrp, lemma: Sfrp, tag: NNP, outgoing: (), incoming: ((4,nsubj)))  (word: is, lemma: be, tag: VBZ, outgoing: (), incoming: ((4,cop)))  (word: a, lemma: a, tag: DT, outgoing: (), incoming: ((4,det)))  (word: central, lemma: central, tag: JJ, outgoing: (), incoming: ((4,amod)))  (word: regulator, lemma: regulator, tag: NN, outgoing: ((0,nsubj) (1,cop) (2,det) (3,amod) (7,nmod_of) (11,cc) (20,conj_and) (31,conj_and)), incoming: ())  (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((7,case)))  (word: Wnt11, lemma: wnt11, tag: NN, outgoing: (), incoming: ((7,compound)))  (word: signalling, lemma: signalling, tag: NN, outgoing: ((5,case) (6,compound) (9,nmod)), incoming: ((4,nmod_of)))  (word: [, lemma: [, tag: -LRB-, outgoing: (), incoming: ())  (word: 31, lemma: 31, tag: CD, outgoing: (), incoming: ((7,nmod)))  (word: ], lemma: ], tag: -RRB-, outgoing: (), incoming: ())  (word: and, lemma: and, tag: CC, outgoing: (), incoming: ((4,cc)))  (word: its, lemma: its, tag: PRP$, outgoing: (), incoming: ((14,nmod:poss)))  (word: high, lemma: high, tag: JJ, outgoing: (), incoming: ((14,amod)))  (word: expression, lemma: expression, tag: NN, outgoing: ((12,nmod:poss) (13,amod)), incoming: ((20,nsubj) (31,nsubj) (34,nsubjpass:xsubj)))  (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: together, lemma: together, tag: RB, outgoing: ((17,mwe)), incoming: ((18,case)))  (word: with, lemma: with, tag: IN, outgoing: (), incoming: ((16,mwe)))  (word: Wnt11, lemma: wnt11, tag: NN, outgoing: ((16,case)), incoming: ((20,dep)))  (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: suggests, lemma: suggest, tag: VBZ, outgoing: ((14,nsubj) (18,dep) (25,ccomp) (29,cc) (31,conj_and)), incoming: ((4,conj_and)))  (word: that, lemma: that, tag: IN, outgoing: (), incoming: ((25,mark)))  <controller> (word: Art27, lemma: art27, tag: NN, outgoing: (), incoming: ((25,nsubj)))  </controller> <trigger> (word: is, lemma: be, tag: VBZ, outgoing: (), incoming: ((25,cop)))  (word: a, lemma: a, tag: DT, outgoing: (), incoming: ((25,det)))  (word: repressor, lemma: repressor, tag: NN, outgoing: ((21,mark) (22,nsubj) (23,cop) (24,det) (28,nmod_of)), incoming: ((20,ccomp)))  </trigger> (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((28,case)))  <controlled> (word: cardiac, lemma: cardiac, tag: JJ, outgoing: (), incoming: ((28,amod)))  (word: genes, lemma: gene, tag: NNS, outgoing: ((26,case) (27,amod)), incoming: ((25,nmod_of)))  </controlled> (word: and, lemma: and, tag: CC, outgoing: (), incoming: ((20,cc)))  (word: is, lemma: be, tag: VBZ, outgoing: (), incoming: ((31,cop)))  (word: likely, lemma: likely, tag: JJ, outgoing: ((14,nsubj) (30,cop) (34,xcomp)), incoming: ((4,conj_and) (20,conj_and)))  (word: to, lemma: to, tag: TO, outgoing: (), incoming: ((34,mark)))  (word: be, lemma: be, tag: VB, outgoing: (), incoming: ((34,auxpass)))  (word: involved, lemma: involve, tag: VBN, outgoing: ((14,nsubjpass:xsubj) (32,mark) (33,auxpass) (37,nmod_in)), incoming: ((31,xcomp)))  (word: in, lemma: in, tag: IN, outgoing: (), incoming: ((37,case)))  (word: the, lemma: the, tag: DT, outgoing: (), incoming: ((37,det)))  (word: maintenance, lemma: maintenance, tag: NN, outgoing: ((35,case) (36,det) (41,nmod_of)), incoming: ((34,nmod_in)))  (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((41,case)))  (word: required, lemma: require, tag: VBN, outgoing: (), incoming: ((41,amod)))  (word: expression, lemma: expression, tag: NN, outgoing: (), incoming: ((41,compound)))  (word: levels, lemma: level, tag: NNS, outgoing: ((38,case) (39,amod) (40,compound)), incoming: ((37,nmod_of)))  (word: ., lemma: ., tag: ., outgoing: (), incoming: ()) \n",
      "\n",
      "Predicted Rule:  ['trigger = [word=/(?i)^(is)/ & tag:^V /\\'nmod\\':np mod,!outgoing=\"tsubj\"&!tag~|--]\\ncontrolled-name=[lemma=(regul)+ | --< \\'con j_/{1,2}PFX\\\\b[xcomp+Technical\\'] >> </\\' nMod :poss\\',3}\\'{0,\\'nglink\":yref\\'sIn$&\\'']\n",
      "\n",
      "True Rule:  trigger = [lemma=/be/ & tag=/^V/] []? []? [lemma=/repress/ & tag=/^N/]\n",
      "controlled:BioEntity = /nmod_of/\n",
      "controller:PossibleController = nsubj\n",
      "\n",
      "--------------------\n",
      "Rule name Positive_activation_syntax_results_in\n",
      "\n",
      "--------------------\n",
      "Text:  (word: Altogether, lemma: altogether, tag: RB, outgoing: (), incoming: ((4,advmod)))  (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  <controller> (word: PKD1, lemma: pkd1, tag: NN, outgoing: (), incoming: ((3,compound)))  </controller> (word: activity, lemma: activity, tag: NN, outgoing: ((2,compound)), incoming: ((4,nsubj)))  (word: results, lemma: result, tag: VBZ, outgoing: ((0,advmod) (3,nsubj) (8,nmod_in)), incoming: ())  (word: in, lemma: in, tag: IN, outgoing: (), incoming: ((8,case)))  <controlled> (word: pro, lemma: pro, tag: JJ, outgoing: (), incoming: ((8,amod)))  (word: survival, lemma: survival, tag: NN, outgoing: (), incoming: ((8,compound)))  </controlled> <trigger> (word: signals, lemma: signal, tag: NNS, outgoing: ((5,case) (6,amod) (7,compound) (11,nmod_in) (13,dep)), incoming: ((4,nmod_in)))  </trigger> (word: in, lemma: in, tag: IN, outgoing: (), incoming: ((11,case)))  (word: oxidative, lemma: oxidative, tag: JJ, outgoing: (), incoming: ((11,amod)))  (word: stress, lemma: stress, tag: NN, outgoing: ((9,case) (10,amod)), incoming: ((8,nmod_in)))  (word: (, lemma: (, tag: -LRB-, outgoing: (), incoming: ())  (word: reviewed, lemma: review, tag: VBN, outgoing: ((15,nmod_in)), incoming: ((8,dep)))  (word: in, lemma: in, tag: IN, outgoing: (), incoming: ((15,case)))  (word: Storz, lemma: Storz, tag: NNP, outgoing: ((14,case) (16,nummod) (21,dep)), incoming: ((13,nmod_in)))  (word: 2007, lemma: 2007, tag: CD, outgoing: (), incoming: ((15,nummod)))  (word: ;, lemma: ;, tag: :, outgoing: (), incoming: ())  (word: Cobbaut, lemma: Cobbaut, tag: NNP, outgoing: ((19,cc) (20,conj_and)), incoming: ((21,compound)))  (word: and, lemma: and, tag: CC, outgoing: (), incoming: ((18,cc)))  (word: Van, lemma: Van, tag: NNP, outgoing: (), incoming: ((18,conj_and) (21,compound)))  (word: Lint, lemma: Lint, tag: NNP, outgoing: ((18,compound) (20,compound) (22,nummod)), incoming: ((15,dep)))  (word: 2018, lemma: 2018, tag: CD, outgoing: (), incoming: ((21,nummod)))  (word: ), lemma: ), tag: -RRB-, outgoing: (), incoming: ())  (word: ., lemma: ., tag: ., outgoing: (), incoming: ()) \n",
      "\n",
      "Predicted Rule:  [\"trigger = [word=/(?i)^(signal)/ & tag:^N|GRU]\\ncontrolled :BioEntity |= /nmod_in$/ | (/'' nsubj-xchg')/{,2}\"]\n",
      "\n",
      "True Rule:  trigger = [word=/(?i)^(signal)/ & tag=/^N/] [lemma=/^(regul)/ & tag=/^N/]?\n",
      "controlled:BioEntity = /amod/\n",
      "controller:PossibleController = </nmod_(in)/ [lemma=result] nsubj /compound/{,2}\n",
      "\n",
      "--------------------\n",
      "Rule name Positive_activation_copula_1\n",
      "\n",
      "--------------------\n",
      "Text:  (word: The, lemma: the, tag: DT, outgoing: (), incoming: ((2,det)))  (word: major, lemma: major, tag: JJ, outgoing: (), incoming: ((2,amod)))  (word: substrate, lemma: substrate, tag: NN, outgoing: ((0,det) (1,amod) (4,nmod_of)), incoming: ((6,nsubj)))  (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((4,case)))  (word: Bace1, lemma: bace1, tag: NN, outgoing: ((3,case)), incoming: ((2,nmod_of)))  (word: is, lemma: be, tag: VBZ, outgoing: (), incoming: ((6,cop)))  (word: APP, lemma: app, tag: NN, outgoing: ((2,nsubj) (5,cop) (8,dep)), incoming: ())  (word: ;, lemma: ;, tag: :, outgoing: (), incoming: ())  (word: cleavage, lemma: cleavage, tag: NN, outgoing: ((11,acl_of)), incoming: ((6,dep)))  (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((11,mark)))  (word: which, lemma: which, tag: WDT, outgoing: (), incoming: ((11,nsubj)))  (word: produces, lemma: produce, tag: VBZ, outgoing: ((9,mark) (10,nsubj) (13,dobj) (16,nmod_with) (22,nmod_by)), incoming: ((8,acl_of)))  (word: sAPP, lemma: sapp, tag: NN, outgoing: (), incoming: ((13,compound)))  (word: beta, lemma: beta, tag: NN, outgoing: ((12,compound)), incoming: ((11,dobj)))  (word: with, lemma: with, tag: IN, outgoing: (), incoming: ((16,case)))  (word: further, lemma: further, tag: JJ, outgoing: (), incoming: ((16,amod)))  (word: cleavage, lemma: cleavage, tag: NN, outgoing: ((14,case) (15,amod) (20,nmod_of)), incoming: ((11,nmod_with)))  (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((20,case)))  (word: the, lemma: the, tag: DT, outgoing: (), incoming: ((20,det)))  (word: membrane, lemma: membrane, tag: NN, outgoing: (), incoming: ((20,compound)))  (word: stub, lemma: stub, tag: NN, outgoing: ((17,case) (18,det) (19,compound)), incoming: ((16,nmod_of)))  (word: by, lemma: by, tag: IN, outgoing: (), incoming: ((22,case)))  (word: gamma-secretase, lemma: gamma-secretase, tag: NN, outgoing: ((21,case) (23,acl)), incoming: ((11,nmod_by)))  (word: forming, lemma: form, tag: VBG, outgoing: ((26,dobj)), incoming: ((22,acl)))  <controlled> (word: A, lemma: a, tag: NN, outgoing: (), incoming: ((26,compound)))  (word: beta, lemma: beta, tag: NN, outgoing: (), incoming: ((26,compound)))  (word: peptides, lemma: peptide, tag: NNS, outgoing: ((24,compound) (25,compound) (29,ref) (38,acl:relcl)), incoming: ((23,dobj) (38,nmod_of)))  </controlled> (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: of, lemma: of, tag: IN, outgoing: (), incoming: ((29,case)))  (word: which, lemma: which, tag: WDT, outgoing: ((28,case)), incoming: ((26,ref)))  <controller> (word: A, lemma: a, tag: NN, outgoing: (), incoming: ((31,compound)))  (word: beta, lemma: beta, tag: NN, outgoing: ((30,compound) (32,cc) (34,conj_and)), incoming: ((38,nsubj)))  </controller> (word: and, lemma: and, tag: CC, outgoing: (), incoming: ((31,cc)))  (word: A, lemma: a, tag: NN, outgoing: (), incoming: ((34,compound)))  (word: beta, lemma: beta, tag: NN, outgoing: ((33,compound)), incoming: ((31,conj_and) (38,nsubj)))  <trigger> (word: are, lemma: be, tag: VBP, outgoing: (), incoming: ((38,cop)))  (word: the, lemma: the, tag: DT, outgoing: (), incoming: ((38,det)))  (word: main, lemma: main, tag: JJ, outgoing: (), incoming: ((38,amod)))  (word: products, lemma: product, tag: NNS, outgoing: ((26,nmod_of) (31,nsubj) (34,nsubj) (35,cop) (36,det) (37,amod)), incoming: ((26,acl:relcl)))  </trigger> (word: ., lemma: ., tag: ., outgoing: (), incoming: ()) \n",
      "\n",
      "Predicted Rule:  ['trigger = [word=/(?i)^(be)/ & tag:VBP]\\ncontrolled :BioEntity += (>/nsubjpass,tag!=\"^v/\")? /compound/{1}controller.html#\\' nmod_of\\':np mod,2}){0,\"sensitivity\"}/{3},']\n",
      "\n",
      "True Rule:  trigger = [lemma=/be/ & tag=/^V/] []? []? [lemma=/produc/ & tag=/^N/]\n",
      "controlled:BioEntity = /nmod_of/\n",
      "controller:PossibleController = nsubj\n",
      "\n",
      "--------------------\n",
      "Rule name Positive_activation_syntax_4_verb\n",
      "\n",
      "--------------------\n",
      "Text:  (word: Here, lemma: here, tag: RB, outgoing: (), incoming: ((3,advmod)))  (word: ,, lemma: ,, tag: ,, outgoing: (), incoming: ())  (word: we, lemma: we, tag: PRP, outgoing: (), incoming: ((3,nsubj)))  (word: show, lemma: show, tag: VBP, outgoing: ((0,advmod) (2,nsubj) (11,ccomp)), incoming: ())  (word: that, lemma: that, tag: IN, outgoing: (), incoming: ((11,mark)))  <controlled> (word: PARP, lemma: parp, tag: NN, outgoing: (), incoming: ((6,compound)))  </controlled> (word: activity, lemma: activity, tag: NN, outgoing: ((5,compound) (9,nmod_during)), incoming: ((11,nsubjpass)))  (word: during, lemma: during, tag: IN, outgoing: (), incoming: ((9,case)))  (word: photoreceptor, lemma: photoreceptor, tag: NN, outgoing: (), incoming: ((9,compound)))  (word: neurodegeneration, lemma: neurodegeneration, tag: NN, outgoing: ((7,case) (8,compound)), incoming: ((6,nmod_during)))  (word: is, lemma: be, tag: VBZ, outgoing: (), incoming: ((11,auxpass)))  <trigger> (word: caused, lemma: cause, tag: VBN, outgoing: ((4,mark) (6,nsubjpass) (10,auxpass) (15,nmod_to) (20,advmod)), incoming: ((3,ccomp)))  </trigger> (word: to, lemma: to, tag: TO, outgoing: (), incoming: ((15,case)))  (word: a, lemma: a, tag: DT, outgoing: (), incoming: ((15,det)))  (word: major, lemma: major, tag: JJ, outgoing: (), incoming: ((15,amod)))  (word: extent, lemma: extent, tag: NN, outgoing: ((12,case) (13,det) (14,amod) (19,nmod_by)), incoming: ((11,nmod_to)))  (word: by, lemma: by, tag: IN, outgoing: (), incoming: ((19,case)))  (word: the, lemma: the, tag: DT, outgoing: (), incoming: ((19,det)))  <controller> (word: PARP1, lemma: parp1, tag: NN, outgoing: (), incoming: ((19,compound)))  </controller> (word: isoform, lemma: isoform, tag: NN, outgoing: ((16,case) (17,det) (18,compound)), incoming: ((15,nmod_by)))  (word: specifically, lemma: specifically, tag: RB, outgoing: (), incoming: ((11,advmod)))  (word: ., lemma: ., tag: ., outgoing: (), incoming: ()) \n",
      "\n",
      "Predicted Rule:  ['trigger = [word=/(?i)^(caus)/ & tag:VBN] [-lemma=\"regulate\"&!outgoing=[nsubjpass,2]}\\ncontrolled :BioEntity |= appos|con j_ /\\'</\\'sensitivity\\':npmod,numMod/{1} | application|\\'ccomp:\\'r subJ-xtra\\', ndep!=\\'ntimbers\\') {{{3,\\'ngp\":possibl}\\'/?']\n",
      "\n",
      "True Rule:  trigger = [word=/(?i)^(caus)/ & tag=/^V/] [lemma=/^(activ)/ & tag=/^V/]?\n",
      "controlled:BioEntity = (nsubjpass /compound/{,2})\n",
      "controller:PossibleController = (/nmod_/ /advmod/{,2})? /nmod_/{,2} /nmod_by/ /compound/{,2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in val_rules.items():\n",
    "    print(\"--------------------\")\n",
    "    print(\"Rule name\", key)\n",
    "    print()\n",
    "    for i in range(1):\n",
    "        text = value[i].text\n",
    "        print(\"--------------------\")\n",
    "        print(\"Text: \", text)\n",
    "        print()\n",
    "        print(\"Predicted Rule: \", generate_rule(text, trained_model, roberta_tokenizer))\n",
    "        print()\n",
    "        print(\"True Rule: \", value[i].rule)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09d3801-1263-4891-b242-cef4a2e6d7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
